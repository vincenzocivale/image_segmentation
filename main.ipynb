{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "project_home_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "sys.path.append(project_home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "\n",
    "from src.data_preprocessing import prepare_dataset\n",
    "from src.model import train_segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_rgb_values = {\n",
    "    0: [0, 0, 255],      # Class 0 is represented by blue pixels\n",
    "    1: [0, 255, 0],      # Class 1 is represented by green pixels\n",
    "    2: [255, 0, 0],      # Class 2 is represented by red pixels\n",
    "    3: [255, 85, 255],    # Class 3 is represented by pink pixels\n",
    "    #4: [0, 170, 255    # Class 4 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset caricato: 646 immagini con maschere corrispondenti\n",
      "Divisione dataset: 451 train, 65 validation, 130 test\n",
      "Dataset caricato: 646 immagini con maschere corrispondenti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inside-tech/Desktop/image_segmentation/src/data_preprocessing.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'mask': torch.tensor(class_mask, dtype=torch.long),\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"/home/inside-tech/Desktop/image_segmentation/data/raw/_4_classi/images\"\n",
    "mask_dir = \"/home/inside-tech/Desktop/image_segmentation/data/raw/_4_classi/labels\"\n",
    "\n",
    "wandb.init(project=\"CowSegmentation\", name=\"SegFormer\")\n",
    "\n",
    "# Prepara dataloader\n",
    "train_loader, val_loader, test_loader, full_dataset = prepare_dataset(\n",
    "    img_dir=img_dir,\n",
    "    mask_dir=mask_dir,\n",
    "    class_rgb_values=class_rgb_values,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Calcola i pesi delle classi per il bilanciamento\n",
    "class_weights = full_dataset.get_class_weight()\n",
    "\n",
    "# Esegui il training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trainer = train_segformer(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_classes=len(class_rgb_values),\n",
    "    epochs=30,\n",
    "    learning_rate=1e-4,\n",
    "    device=device,\n",
    "    class_weights=class_weights\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
