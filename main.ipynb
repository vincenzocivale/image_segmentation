{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "project_home_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "sys.path.append(project_home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/inside-tech/Desktop/image_segmentation/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "\n",
    "from src.data_preprocessing import prepare_dataset\n",
    "from src.model import train_segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_rgb_values = {\n",
    "    1: [0, 0, 255],      # Class 0 is represented by blue pixels\n",
    "    2: [0, 255, 0],      # Class 1 is represented by green pixels\n",
    "    3: [255, 0, 0],      # Class 2 is represented by red pixels\n",
    "    4: [255, 85, 255],    # Class 3 is represented by pink pixels\n",
    "    #4: [0, 170, 255    # Class 4 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvincenzo-civale\u001b[0m (\u001b[33mvincenzo-civale-universi-degli-studi-di-firenze\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/inside-tech/Desktop/image_segmentation/wandb/run-20250322_174818-a5q9huyd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/CowSegmentation/runs/a5q9huyd' target=\"_blank\">SegFormer</a></strong> to <a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/CowSegmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/CowSegmentation' target=\"_blank\">https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/CowSegmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/CowSegmentation/runs/a5q9huyd' target=\"_blank\">https://wandb.ai/vincenzo-civale-universi-degli-studi-di-firenze/CowSegmentation/runs/a5q9huyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricate 646 immagini\n",
      "Dataset caricato: 646 immagini con maschere corrispondenti\n",
      "Divisione dataset: 451 train, 65 validation, 130 test\n",
      "Caricate 646 immagini\n",
      "Dataset caricato: 646 immagini con maschere corrispondenti\n"
     ]
    }
   ],
   "source": [
    "img_dir = \"/home/inside-tech/Desktop/image_segmentation/data/raw/_4_classi/images\"\n",
    "mask_dir = \"/home/inside-tech/Desktop/image_segmentation/masks\"\n",
    "\n",
    "wandb.init(project=\"CowSegmentation\", name=\"SegFormer\")\n",
    "\n",
    "# Prepara dataloader\n",
    "train_loader, val_loader, test_loader, full_dataset = prepare_dataset(\n",
    "    img_dir=img_dir,\n",
    "    mask_dir=mask_dir,\n",
    "    class_rgb_values=class_rgb_values,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Calcola i pesi delle classi per il bilanciamento\n",
    "class_weights = full_dataset.get_class_weight()\n",
    "\n",
    "# Esegui il training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trainer = train_segformer(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_classes=len(class_rgb_values),\n",
    "    epochs=30,\n",
    "    learning_rate=1e-4,\n",
    "    device=device,\n",
    "    class_weights=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# import cv2\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def extract_binary_masks(input_path, output_path, class_rgb_values):\n",
    "#     \"\"\"\n",
    "#     Estrae maschere binarie per ogni classe RGB presente nelle immagini di segmentazione.\n",
    "\n",
    "#     Args:\n",
    "#         input_path (str): Percorso alla directory contenente le immagini di segmentazione.\n",
    "#         output_path (str): Percorso dove salvare le maschere binarie.\n",
    "#         class_rgb_values (dict): Dizionario che mappa l'indice di classe ai valori RGB corrispondenti.\n",
    "#     \"\"\"\n",
    "#     # Crea la directory di output se non esiste\n",
    "#     os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "#     # Crea sottodirectory per ogni classe\n",
    "#     for class_idx in class_rgb_values:\n",
    "#         class_dir = os.path.join(output_path, f\"class_{class_idx}\")\n",
    "#         os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "#     # Lista tutti i file nella directory di input\n",
    "#     image_files = [f for f in os.listdir(input_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif'))]\n",
    "\n",
    "#     for image_file in tqdm(image_files, desc=\"Elaborazione immagini\"):\n",
    "#         # Carica l'immagine\n",
    "#         img_path = os.path.join(input_path, image_file)\n",
    "#         img = cv2.imread(img_path)\n",
    "\n",
    "#         if img is None:\n",
    "#             print(f\"Errore nel caricamento dell'immagine: {img_path}\")\n",
    "#             continue\n",
    "\n",
    "#         # Converti da BGR a RGB (OpenCV carica come BGR)\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         # Estrai il nome del file senza estensione\n",
    "#         file_name = os.path.splitext(image_file)[0]\n",
    "\n",
    "#         # Per ogni classe, crea una maschera binaria\n",
    "#         for class_idx, rgb_value in class_rgb_values.items():\n",
    "#             # Crea una maschera dove i pixel corrispondono esattamente al valore RGB\n",
    "#             mask = np.all(img == rgb_value, axis=2).astype(np.uint8) * 255\n",
    "\n",
    "#             # Verifica se la classe Ã¨ presente nell'immagine (almeno un pixel)\n",
    "#             if np.any(mask):\n",
    "#                 # Salva la maschera binaria\n",
    "#                 mask_path = os.path.join(output_path, f\"class_{class_idx}\", f\"{file_name}_class{class_idx}.png\")\n",
    "#                 cv2.imwrite(mask_path, mask)\n",
    "\n",
    "\n",
    "# class_rgb_values = {\n",
    "#         1: [0, 0, 255],        # Class 0 - blu\n",
    "#         2: [0, 255, 0],        # Class 1 - verde\n",
    "#         3: [255, 0, 0],        # Class 2 - rosso\n",
    "#         4: [255, 85, 255],     # Class 3 - rosa\n",
    "#         5: [0, 170, 255]       # Class 4 - azzurro\n",
    "#   }\n",
    "\n",
    "#     # Percorsi di input e output\n",
    "# input_path = \"/home/inside-tech/Desktop/image_segmentation/data/raw/_4_classi/labels\"\n",
    "# output_path = \"/home/inside-tech/Desktop/image_segmentation/masks\"\n",
    "\n",
    "#     # Esegui l'estrazione delle maschere\n",
    "# extract_binary_masks(input_path, output_path, class_rgb_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
